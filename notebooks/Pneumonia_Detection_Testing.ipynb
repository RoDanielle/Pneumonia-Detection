{"cells":[{"cell_type":"markdown","metadata":{"id":"NiT8Dz-KOkO0"},"source":["**Author:**\n","\n","*   Danielle Rotem \n","\n","**Description**:\n","\n","Testing notebook for pneumonia detection using chest x ray project.\n","\n","**User guide:**\n","\n","copy into your Google Drive root directory the folder \"models_and_weights\" from https://drive.google.com/drive/folders/1EIkepDGTZes43p2omPLophCPT3GPlYL_?usp=sharing \n","\n","Please follow each assignment guide in order to run its test."]},{"cell_type":"markdown","metadata":{"id":"5q4xMlKzgSJy"},"source":["# MODEL A1"]},{"cell_type":"markdown","metadata":{"id":"qIdS-wNwWaHl"},"source":["##Description: get a binary classification (normal or pneumonia) for a new image"]},{"cell_type":"markdown","metadata":{"id":"pz6texFSOL3l"},"source":["## Instructions:\n","1. make sure you have this path in your google drive: /content/drive/My Drive/models_and_weights/A1/\n","2. make sure **A1** contais these two files: **'model.keras'** and **'weights.model.keras'**\n","3. run \"load before testing\"\n","4. in \"test new data\" - provide a path to the image(s) you want to test.\n","  * The images must be saved in your google drive.\n","  * The images or folder must be extracted and not in a zip.\n","5. run \"test new data\"\n"]},{"cell_type":"markdown","metadata":{"id":"bdQty0JQY275"},"source":["##load before testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKz-_AdEZAkd"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","\n","def load_model_and_weights():\n","    # Define the directory path where the model and weights are saved\n","    directory_path = '/content/drive/My Drive/models_and_weights/A1/'\n","    # Load the model architecture\n","    model_path = os.path.join(directory_path, 'model.keras')\n","    model = load_model(model_path)\n","    # Load the model weights\n","    weights_path = os.path.join(directory_path, 'weights.model.keras')\n","    model.load_weights(weights_path)\n","    return model  # Return the loaded model\n","\n","def preprocess_input_data(input_data):\n","    preprocessed_data = []\n","    file_paths = []\n","    target_size = (224, 224)\n","\n","    def process_folder(folder):\n","        for filename in os.listdir(folder):\n","            file_path = os.path.join(folder, filename)\n","            if os.path.isdir(file_path):\n","                # Recursively process subfolders\n","                process_folder(file_path)\n","            elif filename.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","                # Process image files\n","                img = cv2.imread(file_path)\n","                img = cv2.resize(img, target_size)\n","                preprocessed_data.append(img)\n","                file_paths.append(file_path)\n","\n","    if os.path.isdir(input_data):\n","        process_folder(input_data)\n","    elif os.path.isfile(input_data) and input_data.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","        # If input_data is a single image file, preprocess that image\n","        img = cv2.imread(input_data)\n","        img = cv2.resize(img, target_size)\n","        preprocessed_data.append(img)\n","        file_paths.append(input_data)\n","\n","    return preprocessed_data, file_paths\n","\n","\n","def display_images(normal_images, pneumonia_images, normal_file_paths, pneumonia_file_paths):\n","    for img, file_path in zip(normal_images, normal_file_paths):\n","        image_name = os.path.basename(file_path)  # Extract the image name from the file path\n","        plt.figure(figsize=(4, 4))\n","        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        plt.axis('off')\n","        plt.show()\n","        print(f\"Prediction: Normal, Image Name: {image_name}\")\n","    for img, file_path in zip(pneumonia_images, pneumonia_file_paths):\n","        image_name = os.path.basename(file_path)  # Extract the image name from the file path\n","        plt.figure(figsize=(4, 4))\n","        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        plt.axis('off')\n","        plt.show()\n","        print(f\"Prediction: Pneumonia, Image Name: {image_name}\")\n","\n","def predictions_graph(normal, pneumonia):\n","    normal_count = len(normal)\n","    pneumonia_count = len(pneumonia)\n","    plt.figure(figsize=(15, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.bar(['Normal', 'Pneumonia'], [normal_count, pneumonia_count], color=['blue', 'red'])\n","    plt.xlabel('Class')\n","    plt.ylabel('Count')\n","    plt.title('Predicted Class Distribution')\n","\n","def get_prediction_A1(data):\n","    drive.mount('/content/drive', force_remount=True)\n","    #load model\n","    model = load_model_and_weights()\n","    # Preprocess the new input data\n","    preprocessed_data, file_paths = preprocess_input_data(data)\n","    # Perform predictions\n","    predictions = model.predict(np.array(preprocessed_data))\n","    # Define class labels\n","    class_labels = ['Normal', 'Pneumonia']\n","    # Initialize lists to store image paths for each class\n","    normal_images = []\n","    pneumonia_images = []\n","    # Convert binary predictions to class labels and store corresponding image paths\n","    for i in range(len(preprocessed_data)):\n","        predicted_class = class_labels[int(predictions[i][0] > 0.5)]\n","        if predicted_class == 'Normal':\n","            normal_images.append(preprocessed_data[i])\n","        else:\n","            pneumonia_images.append(preprocessed_data[i])\n","    # Display images\n","    predictions_graph(normal_images, pneumonia_images)\n","    # Display images\n","    display_images(normal_images, pneumonia_images, file_paths[:len(normal_images)], file_paths[len(normal_images):])"]},{"cell_type":"markdown","metadata":{"id":"Kf1YoUqBYz0b"},"source":["##test new data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vXtY6ALaY17w"},"outputs":[],"source":["# --------------------------------- test ----------------------------------------------\n","\n","#new_data = # Replace with your actual directory path  - for example \"/content/drive/My Drive/IMAGES/\"\n","\n","new_data = \"/content/drive/My Drive/IMG/\"\n","\n","get_prediction_A1(new_data)"]},{"cell_type":"markdown","metadata":{"id":"1MhgFRxKLkJo"},"source":["# MODEL A2"]},{"cell_type":"markdown","metadata":{"id":"XBbPS_w1W6YM"},"source":["##Description: get a multi class classification (normal, virus or bacteria) for a new image\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"t2F0aR3DTTzt"},"source":["## Instructions:\n","1. make sure you have this path in your google drive: /content/drive/My Drive/models_and_weights/A2/\n","2. make sure **A2** contais these two files: **'model.keras'** and **'weights.model.keras'**\n","3. run \"load before testing\"\n","4. in \"test new data\" - provide a path to the image(s) you want to test.\n","  * The images must be saved in your google drive.\n","  * The images or folder must be extracted and not in a zip.\n","5. run \"test new data\"\n"]},{"cell_type":"markdown","metadata":{"id":"ktXW0cMkTfdu"},"source":["##load before testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZX9vXkzdLnqA"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","\n","def load_model_and_weights():\n","    # Define the directory path where the model and weights are saved\n","    directory_path = '/content/drive/My Drive/models_and_weights/A2/'\n","    # Load the model architecture\n","    model_path = os.path.join(directory_path, 'model.keras')\n","    model = load_model(model_path)\n","    # Load the model weights\n","    weights_path = os.path.join(directory_path, 'weights.model.keras')\n","    model.load_weights(weights_path)\n","    return model  # Return the loaded model\n","\n","def preprocess_input_data(input_data):\n","    preprocessed_data = []\n","    file_paths = []\n","    target_size = (224, 224)\n","\n","    def process_folder(folder):\n","        for filename in os.listdir(folder):\n","            file_path = os.path.join(folder, filename)\n","            if os.path.isdir(file_path):\n","                # Recursively process subfolders\n","                process_folder(file_path)\n","            elif filename.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","                # Process image files\n","                img = cv2.imread(file_path)\n","                img = cv2.resize(img, target_size)\n","                preprocessed_data.append(img)\n","                file_paths.append(file_path)\n","\n","    if os.path.isdir(input_data):\n","        process_folder(input_data)\n","    elif os.path.isfile(input_data) and input_data.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","        # If input_data is a single image file, preprocess that image\n","        img = cv2.imread(input_data)\n","        img = cv2.resize(img, target_size)\n","        preprocessed_data.append(img)\n","        file_paths.append(input_data)\n","\n","    return preprocessed_data, file_paths\n","\n","def display_images(images, labels, file_paths):\n","    for img, label, file_path in zip(images, labels, file_paths):\n","        image_name = os.path.basename(file_path)  # Extract the image name from the file path\n","        plt.figure(figsize=(4, 4))\n","        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        plt.axis('off')\n","        plt.show()\n","        print(f\"Prediction: {label}, Image Name: {image_name}\")\n","\n","def predictions_graph(predictions, class_labels):\n","    class_counts = {label: 0 for label in class_labels}\n","    for prediction in predictions:\n","        predicted_class = class_labels[np.argmax(prediction)]\n","        class_counts[predicted_class] += 1\n","\n","    plt.figure(figsize=(10, 5))\n","    plt.bar(class_counts.keys(), class_counts.values(), color=['blue', 'green', 'red'])\n","    plt.xlabel('Class')\n","    plt.ylabel('Count')\n","    plt.title('Predicted Class Distribution')\n","    plt.show()\n","\n","def get_prediction_A2(data):\n","    drive.mount('/content/drive', force_remount=True)\n","    #load model\n","    model = load_model_and_weights()\n","    # Preprocess the new input data\n","    preprocessed_data, file_paths = preprocess_input_data(data)\n","    # Perform predictions\n","    predictions = model.predict(np.array(preprocessed_data))\n","    # Define class labels\n","    class_labels = ['bacteria', 'normal', 'virus']\n","    # Display images\n","    predictions_graph(predictions, class_labels)\n","    # Convert predictions to class labels\n","    predicted_labels = [class_labels[np.argmax(pred)] for pred in predictions]\n","    # Display images\n","    display_images(preprocessed_data, predicted_labels, file_paths)"]},{"cell_type":"markdown","metadata":{"id":"rZ97r9wUZCDz"},"source":["##test new data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTPgQOJoRsCo"},"outputs":[],"source":["# --------------------------------- test ----------------------------------------------\n","\n","new_data = # Replace with your actual directory path  - for example \"/content/drive/My Drive/IMAGES/\"\n","\n","get_prediction_A2(new_data)"]},{"cell_type":"markdown","metadata":{"id":"BN-Wer8lxLTo"},"source":["# MODEL B"]},{"cell_type":"markdown","metadata":{"id":"CKKYn-m6XNee"},"source":["##Description: get a classification using knn and trained embedding vectors for a new image\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"h5Fevh4dyZik"},"source":["## Binary Prediction ('Normal', 'Pneumonia')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Y5N2Gl5qTvpE"},"source":["### Instructions:\n","1. make sure you have this path in your google drive: /content/drive/My Drive/models_and_weights/A1/\n","2. make sure **A1** contais these three files: **'model.keras'** and **'weights.model.keras'**\n","3.make sure you have this path in your google drive: /content/drive/My Drive/models_and_weights/B/binary/\n","4. make sure **binary** contais this file: **knn_classifier.pkl**\n","5. run \"load before testing\"\n","6. in \"test new data\" - provide a path to the image you want to test.\n","  * The images must be saved in your google drive.\n","  * the path must be to a single image\n","7. run \"test new data\""]},{"cell_type":"markdown","metadata":{"id":"lwQY9cUYjcGm"},"source":["### load before testing\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4cxo08ni8wA"},"outputs":[],"source":["import os\n","import cv2\n","import joblib\n","import numpy as np\n","from google.colab import drive\n","from tensorflow.keras import models\n","from google.colab.patches import cv2_imshow\n","from tensorflow.keras.models import load_model\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","def load_model_and_weights():\n","    # Define the directory path where the model and weights are saved\n","    directory_path = '/content/drive/My Drive/models_and_weights/A1/'\n","    # Load the model architecture\n","    model_path = os.path.join(directory_path, 'model.keras')\n","    model = load_model(model_path)\n","    # Load the model weights\n","    weights_path = os.path.join(directory_path, 'weights.model.keras')\n","    model.load_weights(weights_path)\n","    return model  # Return the loaded model\n","\n","def preprocess_input_data(input_data):\n","    preprocessed_data = []\n","    file_paths = []\n","    target_size = (224, 224)\n","    if os.path.isfile(input_data) and input_data.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","        # If input_data is a single image file, preprocess that image\n","        img_path = input_data\n","        img = cv2.imread(img_path)\n","        if img is not None:\n","            img = cv2.resize(img, target_size)\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n","            preprocessed_data.append(img)\n","            file_paths.append(img_path)\n","        else:\n","            print(\"Warning: Unable to read the image file.\")\n","    else:\n","        print(\"Warning: Input data must be a path to a single image file with extension '.png', '.jpg', '.jpeg', or '.gif'.\")\n","\n","    return preprocessed_data, file_paths\n","\n","def load_knn_model():\n","    # Load the trained classifier from Google Drive\n","    knn_classifier_loaded = joblib.load('/content/drive/My Drive/models_and_weights/B/binary/knn_classifier.pkl')\n","    return knn_classifier_loaded\n","\n","\n","def get_Binary_prediction(image_path):\n","    drive.mount('/content/drive', force_remount=True)\n","    # Preprocess the input image\n","    preprocessed_data, file_paths = preprocess_input_data(image_path)\n","    # Ensure that preprocessed_data is not empty\n","    if not preprocessed_data:\n","        print(\"Error: No valid images found.\")\n","        return\n","    # Load model and embedding vectors\n","    model = load_model_and_weights()\n","    embedding_model = models.Model(inputs=model.input, outputs=model.layers[-4].output)\n","    # Get the embedding vectors for the input images\n","    img_embeddings = embedding_model.predict(np.array(preprocessed_data))\n","    knn_classifier = load_knn_model()\n","    # Predict the class labels of the input image embedding vectors\n","    predicted_class = knn_classifier.predict(img_embeddings)\n","    if(predicted_class == 1):\n","      predicted_class = 'Pneumonia'\n","    else:\n","      predicted_class = 'Normal'\n","\n","    image_name = os.path.basename(file_paths[0])  # Extract the filename from the path\n","    print(f\"Predicted Class for {image_name} is: {predicted_class}\")\n","    # Display the preprocessed image\n","    cv2_imshow(preprocessed_data[0])\n"]},{"cell_type":"markdown","metadata":{"id":"vWZft82jjegP"},"source":["### test new image\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L5RKDsoQxOiU"},"outputs":[],"source":["# --------------------------------- test ----------------------------------------------\n","\n","new_data = # Replace with your actual directory path  - for example \"/content/drive/My Drive/IMAGES/image.jpeg\"\n","\n","get_Binary_prediction(new_data)"]},{"cell_type":"markdown","metadata":{"id":"7JkNSFl5ymub"},"source":["## Multi Class Prediction ('Bacteria', 'Normal', 'Virus')"]},{"cell_type":"markdown","metadata":{"id":"ovLUBmSCUohE"},"source":["### Instructions:\n","1. make sure you have this path in your google drive: /content/drive/My Drive/models_and_weights/A2/\n","2. make sure **A2** contais these three files: **'model.keras'** and **'weights.model.keras'**\n","3.make sure you have this path in your google drive: /content/drive/My Drive/models_and_weights/B/multiclass/\n","4. make sure **multiclass** contais this file: **knn_classifier.pkl**\n","5. run \"load before testing\"\n","6. in \"test new data\" - provide a path to the image you want to test.\n","  * The images must be saved in your google drive.\n","  * the path must be to a single image\n","7. run \"test new data\""]},{"cell_type":"markdown","metadata":{"id":"shr3dXVYjwR9"},"source":["### load before testing\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OaH4PyFL9HRy"},"outputs":[],"source":["import os\n","import cv2\n","import joblib\n","import numpy as np\n","from google.colab import drive\n","from tensorflow.keras import models\n","from google.colab.patches import cv2_imshow\n","from tensorflow.keras.models import load_model\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","def load_model_and_weights():\n","    # Define the directory path where the model and weights are saved\n","    directory_path = '/content/drive/My Drive/models_and_weights/A2/'\n","    # Load the model architecture\n","    model_path = os.path.join(directory_path, 'model.keras')\n","    model = load_model(model_path)\n","    # Load the model weights\n","    weights_path = os.path.join(directory_path, 'weights.model.keras')\n","    model.load_weights(weights_path)\n","    return model  # Return the loaded model\n","\n","def preprocess_input_data(input_data):\n","    preprocessed_data = []\n","    file_paths = []\n","    target_size = (224, 224)\n","    if os.path.isfile(input_data) and input_data.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","        # If input_data is a single image file, preprocess that image\n","        img_path = input_data\n","        img = cv2.imread(img_path)\n","        if img is not None:\n","            img = cv2.resize(img, target_size)\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n","            preprocessed_data.append(img)\n","            file_paths.append(img_path)\n","        else:\n","            print(\"Warning: Unable to read the image file.\")\n","    else:\n","        print(\"Warning: Input data must be a path to a single image file with extension '.png', '.jpg', '.jpeg', or '.gif'.\")\n","\n","    return preprocessed_data, file_paths\n","\n","def load_knn_model():\n","    # Load the trained classifier from Google Drive\n","    knn_classifier_loaded = joblib.load('/content/drive/My Drive/models_and_weights/B/multiclass/knn_classifier.pkl')\n","    return knn_classifier_loaded\n","\n","def get_MultiClass_prediction(image_path):\n","    drive.mount('/content/drive', force_remount=True)\n","    # Preprocess the input image\n","    preprocessed_data, file_paths = preprocess_input_data(image_path)\n","    # Ensure that preprocessed_data is not empty\n","    if not preprocessed_data:\n","        print(\"Error: No valid images found.\")\n","        return\n","    # Load model and embedding vectors\n","    model = load_model_and_weights()\n","    embedding_model = models.Model(inputs=model.input, outputs=model.layers[-4].output)\n","    # Get the embedding vectors for the input images\n","    img_embeddings = embedding_model.predict(np.array(preprocessed_data))\n","    knn_classifier = load_knn_model()\n","    # Predict the class labels of the input image embedding vectors\n","    predicted_classes = knn_classifier.predict(img_embeddings)\n","\n","    image_name = os.path.basename(file_paths[0])  # Extract the filename from the path\n","    print(f\"Predicted Class for {image_name} is: {predicted_classes[0]}\")\n","     # Display the preprocessed image\n","    cv2_imshow(preprocessed_data[0])"]},{"cell_type":"markdown","metadata":{"id":"0Z95sc1Oj0mx"},"source":["### test new image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vEh0yv1qj2DS"},"outputs":[],"source":["# --------------------------------- test ----------------------------------------------\n","\n","new_data = # Replace with your actual directory path  - for example \"/content/drive/My Drive/IMAGES/image.jpeg\"\n","\n","get_MultiClass_prediction(new_data)"]},{"cell_type":"markdown","metadata":{"id":"cEcBWbiQxQRQ"},"source":["# MODEL D"]},{"cell_type":"markdown","metadata":{"id":"ZNlYqGeaXlwM"},"source":["##Description: detect anomalies -  get a binary classification (normal or anomaly) for a new image"]},{"cell_type":"markdown","metadata":{"id":"pwdBsKkYVG2T"},"source":["## Instructions:\n","1. make sure you have this path in your google drive: /content/drive/My Drive/models_and_weights/D/\n","2. make sure **D** contais these three files: **'model.keras'** , **'weights.model.keras'** and **'threshold.txt'**\n","3. run \"load before testing\"\n","4. in \"test new data\" - provide a path to the image you want to test.\n","  * The images must be saved in your google drive.\n","  * The images or folder must be extracted and not in a zip.\n","5. run \"test new data\"\n"]},{"cell_type":"markdown","metadata":{"id":"b05Pys0SWiEx"},"source":["##load before testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z9ECdLQNxTnv"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from google.colab import drive\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.backend import eval\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","\n","\n","def load_model_and_threshold():\n","    # Define the directory path where the model and weights are saved\n","    directory_path = '/content/drive/My Drive/models_and_weights/D/'\n","    # Load the model architecture\n","    model_path = os.path.join(directory_path, 'model.keras')\n","    model = load_model(model_path)\n","    # Load the model weights\n","    weights_path = os.path.join(directory_path, 'weights.model.keras')\n","    model.load_weights(weights_path)\n","    # Define the filepath for the threshold file\n","    threshold_file_path = '/content/drive/My Drive/models_and_weights/D/threshold.txt'\n","    # Load the threshold from the file\n","    with open(threshold_file_path, 'r') as file:\n","      threshold = float(file.read())\n","    return model, threshold\n","\n","def preprocess_input_data(input_data):\n","    preprocessed_data = []\n","    file_paths = []\n","    target_size = (224, 224)\n","\n","    def process_folder(folder):\n","        for filename in os.listdir(folder):\n","            file_path = os.path.join(folder, filename)\n","            if os.path.isdir(file_path):\n","                # Recursively process subfolders\n","                process_folder(file_path)\n","            elif filename.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","                # Process image files\n","                img = cv2.imread(file_path)\n","                img = cv2.resize(img, target_size)\n","                img_float = img.astype('float32')\n","                img_normalized = img_float / 255.0\n","                preprocessed_data.append(img_normalized)\n","                file_paths.append(file_path)\n","\n","    if os.path.isdir(input_data):\n","        process_folder(input_data)\n","    elif os.path.isfile(input_data) and input_data.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n","        # If input_data is a single image file, preprocess that image\n","        img = cv2.imread(input_data)\n","        img = cv2.resize(img, target_size)\n","        img_float = img.astype('float32')\n","        img_normalized = img_float / 255.0\n","        preprocessed_data.append(img_normalized)\n","        file_paths.append(input_data)\n","    else:\n","        raise ValueError(\"Input data must be a path to a single image file, a folder containing images, or a folder that contains subfolders with images.\")\n","\n","    return np.array(preprocessed_data), np.array(file_paths)\n","\n","\n","def display_images(predicted_labels, file_paths, images):\n","    # Extract image names from file paths\n","    image_names = [os.path.basename(path) for path in file_paths]\n","    # Print the predicted label for each image along with the image name\n","    for i, (predicted_label, image_name, image) in enumerate(zip(predicted_labels, image_names, images)):\n","        print(f\"Predicted label for image {image_name} is: {predicted_label}\")\n","        # Display the image using cv2_imshow or any other method\n","        cv2_imshow(image * 255.0)\n","\n","def plot_prediction_counts(predicted_labels):\n","    # Count occurrences of 'NORMAL' and 'ANOMALY'\n","    counts = {'NORMAL': predicted_labels.count('NORMAL'), 'ANOMALY': predicted_labels.count('ANOMALY')}\n","    # Plot the counts as a bar graph\n","    plt.bar(counts.keys(), counts.values(), color=['blue', 'red'])\n","    plt.xlabel('Prediction')\n","    plt.ylabel('Count')\n","    plt.title('Prediction Counts')\n","    plt.show()\n","\n","def predict_anomaly(new_data):\n","    drive.mount('/content/drive', force_remount=True)\n","    autoencoder, threshold = load_model_and_threshold()\n","    processed_data, file_paths = preprocess_input_data(new_data)\n","    reconstructed_images_test = autoencoder.predict(processed_data)\n","    test_loss = tf.keras.losses.binary_crossentropy(processed_data, reconstructed_images_test)\n","    test_loss = tf.keras.backend.eval(test_loss)\n","    predicted_labels_test = []\n","    # Iterate over each reconstruction loss in test_loss\n","    for loss in test_loss:\n","        mean_loss = np.mean(loss)\n","        # Check if the loss is greater than the threshold\n","        if mean_loss > threshold:\n","            # If so, append 'anomaly' to the predicted_labels_test list\n","            predicted_labels_test.append('ANOMALY')\n","        else:\n","            # Otherwise, append 'normal'\n","            predicted_labels_test.append('NORMAL')\n","    plot_prediction_counts(predicted_labels_test)\n","    display_images(predicted_labels_test, file_paths, processed_data)"]},{"cell_type":"markdown","metadata":{"id":"9WztgZ9LWux6"},"source":["##test new data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LWaeMs6Wx0L"},"outputs":[],"source":["# --------------------------------- test ----------------------------------------------\n","\n","new_data = # Replace with your actual directory path  - for example \"/content/drive/My Drive/IMAGES/\"\n","\n","predict_anomaly(new_data)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["bdQty0JQY275","Kf1YoUqBYz0b","1MhgFRxKLkJo","t2F0aR3DTTzt","ktXW0cMkTfdu","rZ97r9wUZCDz","lwQY9cUYjcGm","7JkNSFl5ymub","shr3dXVYjwR9","0Z95sc1Oj0mx","cEcBWbiQxQRQ","b05Pys0SWiEx","9WztgZ9LWux6"],"gpuType":"T4","provenance":[{"file_id":"1U7ttxCeUEzQFjEV10mP3yX0bTNR-rTb7","timestamp":1713207109307}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
