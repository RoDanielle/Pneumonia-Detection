{"cells":[{"cell_type":"markdown","metadata":{"id":"R6mQXnlMupLT"},"source":["**Author:**\n","\n","*   Danielle Rotem \n","\n","**Description**:\n","\n","Training notebook for pneumonia detection using chest x ray project."]},{"cell_type":"markdown","metadata":{"id":"dpKJYS62rTWR"},"source":["# MODEL A1 - binary class (Normal, Pneumonia)"]},{"cell_type":"markdown","metadata":{"id":"Ynd82BIRDgiH"},"source":["## Data loading and resizinge"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxbJ6SlgR9wA"},"outputs":[],"source":["from google.colab import drive\n","import os\n","import cv2\n","import numpy as np\n","from zipfile import ZipFile\n","from io import BytesIO\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","\n","# Function to load images from a folder and return X, Y\n","def load_images_from_folder(folder_path, target_size=(224, 224)):\n","    X = []  # Images\n","    y = []  # Labels\n","\n","    for label in os.listdir(folder_path):\n","        label_folder = os.path.join(folder_path, label)\n","\n","        # Ensure it's a directory\n","        if os.path.isdir(label_folder):\n","            for filename in os.listdir(label_folder):\n","                img_path = os.path.join(label_folder, filename)\n","\n","                # Read the image using OpenCV\n","                img = cv2.imread(img_path)\n","                # Resize if needed\n","                img = cv2.resize(img, target_size)\n","\n","                subfolder_name = os.path.basename(label_folder)\n","\n","                # Append image and label to X and y\n","                X.append(img)\n","                y.append(subfolder_name)\n","\n","    return np.array(X), np.array(y)\n","\n","path_train = '/content/drive/MyDrive/project_ML/all_the_images/train'\n","X_train, Y_train = load_images_from_folder(path_train)\n","print(\"X_train shape:\", X_train.shape)\n","print(\"Y_train shape:\", Y_train.shape)\n","\n","# Print the unique labels in y_train\n","unique_labels = np.unique(Y_train)\n","print(\"train Unique Labels:\", unique_labels)\n","\n","# print the count of each label\n","label_counts = {label: np.sum(Y_train == label) for label in unique_labels}\n","print(\"train Label Counts:\", label_counts)\n","\n","path_val = '/content/drive/MyDrive/project_ML/all_the_images/val'\n","X_val, Y_val = load_images_from_folder(path_val)\n","print(\"X_val shape:\", X_val.shape)\n","print(\"Y_val shape:\", Y_val.shape)\n","\n","# Print the unique labels in y_val\n","val_unique_labels = np.unique(Y_val)\n","print(\"val Unique Labels:\", val_unique_labels)\n","\n","# print the count of each label\n","val_label_counts = {label: np.sum(Y_val == label) for label in val_unique_labels}\n","print(\"val Label Counts:\", val_label_counts)"]},{"cell_type":"markdown","metadata":{"id":"MCK2sXcVDj0o"},"source":["## The model - binary class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29R2N3R7b54f"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# Enable eager execution\n","tf.data.experimental.enable_debug_mode()\n","\n","# Image dimensions of 224x224 with 3 channels\n","image_height, image_width, num_channels = 224, 224, 3\n","\n","# Define model\n","model = Sequential()\n","\n","# Convolutional layers\n","model.add(layers.Conv2D(64, (6, 6), strides=(4, 4), activation='relu', padding = 'same', input_shape=(image_height, image_width, num_channels)))\n","\n","#tf.keras.layers.BatchNormalization(),  # Add batch normalization layer after Conv2D\n","\n","model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n","model.add(layers.Conv2D(128, (4, 4), activation='relu', padding = 'same'))\n","model.add(layers.Conv2D(128, (4, 4), activation='relu', padding = 'same'))\n","model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n","model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding = 'same'))\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding = 'same'))\n","model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n","\n","# Flatten layer to convert 3D feature maps to 1D feature vectors\n","model.add(layers.Flatten())\n","\n","# Fully connected layers with dropout\n","model.add(layers.Dense(2048, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification (sigmoid activation)\n","\n","# Compile the model\n","custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","model.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Display the model summary\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"T56auUmqDnh8"},"source":["## Data augmentation and model training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cP2KzicauyTp"},"outputs":[],"source":["import numpy as np\n","import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n","from tensorflow.keras import models\n","from tensorflow.keras.models import load_model\n","\n","# Define the directory path\n","directory_path = '/content/drive/My Drive/models_and_weights/A1/'\n","\n","# Create the directory if it doesn't exist\n","if not os.path.exists(directory_path):\n","    os.makedirs(directory_path)\n","\n","# Save the model architecture to Google Drive\n","model.save('/content/drive/My Drive/models_and_weights/A1/model.keras')\n","\n","# Define the filepath for saving the best weights\n","checkpoint_filepath_binary = '/content/drive/My Drive/models_and_weights/A1/weights.model.keras'\n","\n","# Create an ImageDataGenerator for data augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=15,  # Random rotation up to 20 degrees\n","    zoom_range=0.15,  # Random zoom\n","    horizontal_flip=True,  # Random horizontal flip\n","    vertical_flip=False,    # Random vertical flip\n","    brightness_range=[0.8, 1.2],  # Random brightness adjustment\n","    fill_mode='nearest' # Fill mode for augmentation\n",")\n","\n","# Fit the data augmentation generator on training data\n","datagen.fit(X_train)\n","\n","# Label encoding\n","label_encoder = LabelEncoder()\n","Y_train = label_encoder.fit_transform(Y_train)\n","Y_val = label_encoder.transform(Y_val)\n","\n","# Define EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',   # Monitor validation loss for early stopping\n","    patience=5,            # Stop training after 5 epochs with no improvement\n","    restore_best_weights=True,  # Restore weights to the epoch with the best validation performance\n","    verbose=1             # Print messages indicating early stopping\n",")\n","\n","# Define the ModelCheckpoint callback to save the best weights based on validation loss\n","checkpoint_callback_binary = ModelCheckpoint(\n","    filepath=checkpoint_filepath_binary,\n","    monitor='val_loss',  # Monitor validation loss\n","    save_best_only=True, # Save only the best weights\n","    mode='min',          # Mode for monitoring the validation metric (minimize validation loss)\n","    verbose=1            # Print messages indicating when weights are saved\n",")\n","\n","# Training the binary classification model using model.fit with data augmentation and early stopping\n","history_binary = model.fit(\n","    datagen.flow(X_train, Y_train, batch_size=50),\n","    epochs=10,\n","    validation_data=(X_val, Y_val),\n","    shuffle=True,\n","    callbacks=[early_stopping, checkpoint_callback_binary]\n",")"]},{"cell_type":"markdown","metadata":{"id":"ANCERjdvPd_E"},"source":["## Plot Accuracy and Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-m9j0-ePuDt"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = history_binary.history['accuracy']\n","val_acc = history_binary.history['val_accuracy']\n","loss = history_binary.history['loss']\n","val_loss = history_binary.history['val_loss']\n","epochs = range(len(acc))\n","## Plot accuracy\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.legend(loc=0)\n","plt.figure()\n","plt.show()\n","## Plot Loss\n","plt.plot(epochs, loss, 'r', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation Loss')\n","plt.legend(loc=0)\n","plt.figure()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"c2xLkniYIvan"},"source":["## Loading data for testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubhFFfMmI3aJ"},"outputs":[],"source":["from google.colab import drive\n","import os\n","import cv2\n","import numpy as np\n","from zipfile import ZipFile\n","from io import BytesIO\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Function to load images from a folder and return X, y\n","def load_images_from_folder(folder_path, target_size=(224, 224)):\n","    X = []  # Images\n","    y = []  # Labels\n","\n","    for label in os.listdir(folder_path):\n","        label_folder = os.path.join(folder_path, label)\n","\n","        # Ensure it's a directory\n","        if os.path.isdir(label_folder):\n","            for filename in os.listdir(label_folder):\n","                img_path = os.path.join(label_folder, filename)\n","\n","                # Read the image using OpenCV\n","                img = cv2.imread(img_path)\n","                # Resize if needed\n","                img = cv2.resize(img, target_size)\n","\n","                subfolder_name = os.path.basename(label_folder)\n","\n","                # Append image and label to X and y\n","                X.append(img)\n","                y.append(subfolder_name)\n","\n","    return np.array(X), np.array(y)\n","\n","path_test = '/content/drive/MyDrive/project_ML/all_the_images/test'\n","X_test, Y_test = load_images_from_folder(path_test)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"Y_test shape:\", Y_test.shape)\n","\n","# Print the unique labels in y_test\n","test_unique_labels = np.unique(Y_test)\n","print(\"test Unique Labels:\", test_unique_labels)\n","\n","# print the count of each label\n","test_label_counts = {label: np.sum(Y_test == label) for label in test_unique_labels}\n","print(\"test Label Counts:\", test_label_counts)"]},{"cell_type":"markdown","metadata":{"id":"z7ojPFCtDqXB"},"source":["## Confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QlHcujEjAtrt"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Label encoding for testing data\n","label_encoder = LabelEncoder()\n","Y_test_encoded = label_encoder.fit_transform(Y_test)\n","\n","#Predict labels for the test dataset\n","predicted_labels = (model.predict(X_test) > 0.5).astype(\"int32\")\n","\n","# Convert true labels to binary format (1 for anomaly, 0 for normal)\n","binary_true_labels = np.where(Y_test_encoded == 1, 1, 0)\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(Y_test_encoded, predicted_labels)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Pneumonia'], yticklabels=['Normal', 'Pneumonia'])\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix - Test Dataset')\n","plt.show()\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(binary_true_labels, predicted_labels)\n","precision = precision_score(binary_true_labels, predicted_labels)\n","recall = recall_score(binary_true_labels, predicted_labels, zero_division=1)  # Set zero_division to 1\n","f1 = f1_score(binary_true_labels, predicted_labels)\n","\n","# Print evaluation metrics\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-score:\", f1)"]},{"cell_type":"markdown","metadata":{"id":"7azE_IxKrxaQ"},"source":["# MODEL A2 -multi class (Bacteria, Normal, Virus)\n"]},{"cell_type":"markdown","metadata":{"id":"C9OSWVn4DGOO"},"source":["## Data loading and resizinge"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_2OAZTUTD9T"},"outputs":[],"source":["from google.colab import drive\n","import os\n","import cv2\n","import numpy as np\n","from zipfile import ZipFile\n","from io import BytesIO\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Function to load images from a folder and return X, Y\n","def load_images_from_folder(folder_path):\n","    X = []  # Images\n","    y = []  # Labels\n","\n","    for label in os.listdir(folder_path):\n","        label_folder = os.path.join(folder_path, label)\n","\n","        # Ensure it's a directory\n","        if os.path.isdir(label_folder):\n","            for filename in os.listdir(label_folder):\n","                img_path = os.path.join(label_folder, filename)\n","\n","                # Read the image using OpenCV\n","                img = cv2.imread(img_path)\n","\n","                # Resize if needed\n","                img = cv2.resize(img, (224, 224))\n","\n","                if \"bacteria\" in filename:\n","                  y.append(\"bacteria\")\n","                elif \"virus\" in filename:\n","                  y.append(\"virus\")\n","                else:\n","                  y.append(\"normal\")\n","\n","                # Append image and label to X and y\n","                X.append(img)\n","\n","\n","    return np.array(X), np.array(y)\n","\n","path_train = '/content/drive/MyDrive/project_ML/all_the_images/train'\n","X_train, Y_train = load_images_from_folder(path_train)\n","print(\"X_train shape:\", X_train.shape)\n","print(\"Y_train shape:\", Y_train.shape)\n","\n","# Print the unique labels in y_train\n","unique_labels = np.unique(Y_train)\n","print(\"train Unique Labels:\", unique_labels)\n","\n","# print the count of each label\n","label_counts = {label: np.sum(Y_train == label) for label in unique_labels}\n","print(\"train Label Counts:\", label_counts)\n","\n","path_val = '/content/drive/MyDrive/project_ML/all_the_images/val'\n","X_val, Y_val = load_images_from_folder(path_val)\n","print(\"X_val shape:\", X_val.shape)\n","print(\"Y_val shape:\", Y_val.shape)\n","\n","# Print the unique labels in y_val\n","val_unique_labels = np.unique(Y_val)\n","print(\"val Unique Labels:\", val_unique_labels)\n","\n","# print the count of each label\n","val_label_counts = {label: np.sum(Y_val == label) for label in val_unique_labels}\n","print(\"val Label Counts:\", val_label_counts)"]},{"cell_type":"markdown","metadata":{"id":"zxteJEL3DPDj"},"source":["## The model - multiclass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCoRv448TJSQ"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models, regularizers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# Enable eager execution\n","tf.data.experimental.enable_debug_mode()\n","\n","# Image dimensions of 224x224 with 3 channels\n","image_height, image_width, num_channels = 224, 224, 3\n","\n","# Define model\n","model = Sequential()\n","\n","# Convolutional layers\n","model.add(layers.Conv2D(64, (6, 6), strides=(4, 4), activation='relu', padding = 'same', input_shape=(image_height, image_width, num_channels)))\n","\n","model.add(layers.BatchNormalization()) # Add batch normalization layer after Conv2D\n","\n","model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n","model.add(layers.Conv2D(64, (4, 4), activation='relu', padding = 'same'))\n","model.add(layers.Conv2D(64, (4, 4), activation='relu', padding = 'same'))\n","model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n","model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n","model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n","\n","# Flatten layer to convert 3D feature maps to 1D feature vectors\n","model.add(layers.Flatten())\n","\n","# Fully connected layers with dropout\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(3, activation='softmax'))  # multi classification\n","\n","# Compile the model\n","custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Display the model summary\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"Ps2-IRUlDTFq"},"source":["## Data augmentation and model training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RlKuZK3FT4j8"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import models\n","from tensorflow.keras.models import load_model\n","\n","\n","# Define the directory path\n","directory_path = '/content/drive/My Drive/models_and_weights/A2/'\n","\n","# Create the directory if it doesn't exist\n","if not os.path.exists(directory_path):\n","    os.makedirs(directory_path)\n","\n","# Save the model architecture to Google Drive\n","model.save('/content/drive/My Drive/models_and_weights/A2/model.keras')\n","\n","# Define the filepath for saving the best weights\n","checkpoint_filepath_multiclass = '/content/drive/My Drive/models_and_weights/A2/weights.model.keras'\n","\n","# Create an ImageDataGenerator for data augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=15,  # Random rotation up to 20 degrees\n","    zoom_range=0.15,  # Random zoom\n","    horizontal_flip=True,  # Random horizontal flip\n","    vertical_flip=False,    # Random vertical flip\n","    brightness_range=[0.8, 1.2],  # Random brightness adjustment\n","    fill_mode='nearest' # Fill mode for augmentation\n",")\n","\n","# Fit the data augmentation generator on your training data\n","datagen.fit(X_train)\n","\n","# Label encoding\n","label_encoder = LabelEncoder()\n","Y_train_encoded = label_encoder.fit_transform(Y_train)\n","Y_val_encoded = label_encoder.transform(Y_val)\n","\n","# Convert class labels to one-hot encoding\n","Y_train_one_hot = to_categorical(Y_train_encoded, num_classes=3)\n","Y_val_one_hot = to_categorical(Y_val_encoded, num_classes=3)\n","\n","# Define EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',   # Monitor validation loss for early stopping\n","    patience=5,            # Stop training after 5 epochs with no improvement\n","    restore_best_weights=True,  # Restore weights to the epoch with the best validation performance\n","    verbose=1             # Print messages indicating early stopping\n",")\n","\n","# Define the ModelCheckpoint callback to save the best weights based on validation loss\n","checkpoint_callback_multiclass = ModelCheckpoint(\n","    filepath=checkpoint_filepath_multiclass,\n","    monitor='val_loss',  # Monitor validation loss\n","    save_best_only=True, # Save only the best weights\n","    mode='min',          # Mode for monitoring the validation metric (minimize validation loss)\n","    verbose=1            # Print messages indicating when weights are saved\n",")\n","\n","# Training the multiclass classification model using model.fit with data augmentation and early stopping\n","history_multiclass = model.fit(\n","    datagen.flow(X_train, Y_train_one_hot, batch_size=25),\n","    epochs=16,\n","    validation_data=(X_val, Y_val_one_hot),\n","    shuffle=True,\n","    callbacks=[early_stopping, checkpoint_callback_multiclass]\n",")"]},{"cell_type":"markdown","metadata":{"id":"krsTkEm7VmIk"},"source":["## Plot Accuracy and Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FedK33YZWLtk"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = history_multiclass.history['accuracy']\n","val_acc = history_multiclass.history['val_accuracy']\n","loss = history_multiclass.history['loss']\n","val_loss = history_multiclass.history['val_loss']\n","epochs = range(len(acc))\n","## Plot accuracy\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.legend(loc=0)\n","plt.figure()\n","plt.show()\n","## Plot Loss\n","plt.plot(epochs, loss, 'r', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation Loss')\n","plt.legend(loc=0)\n","plt.figure()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"iokNzLGsJYCT"},"source":["## Loading data for testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3URICZmjJaiV"},"outputs":[],"source":["from google.colab import drive\n","import os\n","import cv2\n","import numpy as np\n","from zipfile import ZipFile\n","from io import BytesIO\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Function to load images from a folder and return X, Y\n","def load_images_from_folder(folder_path):\n","    X = []  # Images\n","    y = []  # Labels\n","\n","    for label in os.listdir(folder_path):\n","        label_folder = os.path.join(folder_path, label)\n","\n","        # Ensure it's a directory\n","        if os.path.isdir(label_folder):\n","            for filename in os.listdir(label_folder):\n","                img_path = os.path.join(label_folder, filename)\n","\n","                # Read the image using OpenCV\n","                img = cv2.imread(img_path)\n","\n","                # Resize if needed\n","                img = cv2.resize(img, (224, 224))\n","\n","                if \"bacteria\" in filename:\n","                  y.append(\"bacteria\")\n","                elif \"virus\" in filename:\n","                  y.append(\"virus\")\n","                else:\n","                  y.append(\"normal\")\n","\n","                # Append image and label to X and y\n","                X.append(img)\n","\n","\n","    return np.array(X), np.array(y)\n","\n","\n","path_test = '/content/drive/MyDrive/project_ML/all_the_images/test'\n","X_test, Y_test = load_images_from_folder(path_test)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"Y_test shape:\", Y_test.shape)\n","\n","# Print the unique labels in y_test\n","test_unique_labels = np.unique(Y_test)\n","print(\"test Unique Labels:\", test_unique_labels)\n","\n","# print the count of each label\n","test_label_counts = {label: np.sum(Y_test == label) for label in test_unique_labels}\n","print(\"test Label Counts:\", test_label_counts)"]},{"cell_type":"markdown","metadata":{"id":"g5S26y9GDXVx"},"source":["## Confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7lc5GOABArz"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","\n","# Label encoding for testing data\n","label_encoder = LabelEncoder()\n","Y_test_encoded = label_encoder.fit_transform(Y_test)\n","\n","# Define the class labels\n","class_labels = ['Bacteria', 'Normal', 'Virus']\n","\n","# Predict labels for the test dataset\n","predicted_labels = np.argmax(model.predict(X_test), axis=1)  # selects the class with the highest probability\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(Y_test_encoded, predicted_labels)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix - Test Dataset')\n","plt.show()\n","\n","# Generate classification report\n","report = classification_report(Y_test_encoded, predicted_labels, target_names=class_labels)\n","print(\"Classification Report:\")\n","print(report)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(Y_test_encoded, predicted_labels)\n","precision = precision_score(Y_test_encoded, predicted_labels, average='weighted')\n","recall = recall_score(Y_test_encoded, predicted_labels, average='weighted')\n","f1 = f1_score(Y_test_encoded, predicted_labels, average='weighted')\n","\n","# Print evaluation metrics\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-score:\", f1)"]},{"cell_type":"markdown","metadata":{"id":"MpCruNYV9XyI"},"source":["\n","# MODEL B - classification using KNN"]},{"cell_type":"markdown","metadata":{"id":"eUqLAfSbwMAT"},"source":["## classifying new image using binary model and KNN\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8_JT0ifO9pFq"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","from sklearn.manifold import TSNE\n","from sklearn.neighbors import KNeighborsClassifier\n","from tensorflow.keras import models\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","import cv2\n","import joblib\n","\n","\n","# Create the embedding model right before the fully connected layers\n","embedding_model = models.Model(inputs=model.input, outputs=model.layers[-4].output)\n","\n","# Use the embedding_model to get the embedding vectors directly\n","embedding_vectors_train = embedding_model.predict(X_train)\n","\n","# Load the new image\n","new_image = \"/content/drive/MyDrive/project_ML/all_the_images/test/PNEUMONIA/person1685_virus_2903.jpeg\"\n","\n","# Read the image using OpenCV\n","img = cv2.imread(new_image)\n","\n","img = cv2.resize(img, (224, 224))\n","\n","# Get the embedding for the new image\n","new_image_embedding = embedding_model.predict(tf.expand_dims(img, axis=0))\n","\n","# Apply kNN on embeddings\n","knn_classifier = KNeighborsClassifier(n_neighbors=3)\n","knn_classifier.fit(embedding_vectors_train, Y_train)\n","\n","# Define the directory path\n","directory_path = '/content/drive/My Drive/models_and_weights/B/binary/'\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(directory_path, exist_ok=True)\n","\n","# Save the trained classifier to Google Drive\n","joblib.dump(knn_classifier, os.path.join(directory_path, 'knn_classifier.pkl'))\n","\n","# Classify the new image using kNN on new image embedding vector\n","predicted_class = knn_classifier.predict(new_image_embedding)\n","\n","decoded_label = label_encoder.inverse_transform(predicted_class)[0]\n","print(f\"Predicted Class: {decoded_label}\")\n","\n","# Display the image using OpenCV\n","cv2_imshow(cv2.imread(new_image))"]},{"cell_type":"markdown","metadata":{"id":"CXb8ca6DOU5b"},"source":["### Visualize the t-SNE embeddings for the training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vg_GjrxA-cVE"},"outputs":[],"source":["# Apply t-SNE on embeddings\n","tsne = TSNE(n_components=2, random_state=42)\n","embedding_tsne = tsne.fit_transform(embedding_vectors_train) # Visualizing Embedding Vectors\n","\n","# Visualize the t-SNE embeddings for the training set\n","plt.scatter(embedding_tsne[:, 0], embedding_tsne[:, 1], c=Y_train, cmap='viridis')\n","plt.title('t-SNE Visualization of Embeddings (Training Set)')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"HdADnls2wcEk"},"source":["## classifying new image using multi class model and KNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ym3UGLyCwbmH"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","from sklearn.manifold import TSNE\n","from sklearn.neighbors import KNeighborsClassifier\n","from tensorflow.keras import models\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","import cv2\n","import joblib\n","\n","# Create the embedding model right before the fully connected layers\n","embedding_model = models.Model(inputs=model.input, outputs=model.layers[-4].output)\n","\n","# Use the embedding_model to get the embedding vectors directly\n","embedding_vectors_train = embedding_model.predict(X_train)\n","\n","# Load the new image\n","new_image = \"/content/drive/MyDrive/project_ML/all_the_images/test/NORMAL/IM-0001-0001.jpeg\"\n","\n","# Read the image using OpenCV\n","img = cv2.imread(new_image)\n","\n","# Resize if needed\n","img = cv2.resize(img, (224, 224))\n","\n","# Get the embedding for the new image\n","new_image_embedding = embedding_model.predict(tf.expand_dims(img, axis=0))\n","\n","# Apply kNN on embeddings\n","knn_classifier = KNeighborsClassifier(n_neighbors=3)\n","knn_classifier.fit(embedding_vectors_train, Y_train)\n","\n","# Define the directory path\n","directory_path = '/content/drive/My Drive/models_and_weights/B/multiclass/'\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(directory_path, exist_ok=True)\n","\n","# Save the trained classifier to Google Drive\n","joblib.dump(knn_classifier, os.path.join(directory_path, 'knn_classifier.pkl'))\n","\n","# Classify the new image using kNN on new image embedding vector\n","predicted_class = knn_classifier.predict(new_image_embedding)\n","print(f\"Predicted Class: {predicted_class}\")\n","\n","# Display the image using OpenCV\n","img = cv2.imread(new_image)\n","resized_img = cv2.resize(img, (400, 400), interpolation=cv2.INTER_AREA)\n","cv2_imshow(resized_img)"]},{"cell_type":"markdown","metadata":{"id":"OUj-PIG0OcrN"},"source":["### Visualize the t-SNE embeddings for the training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCT559Gdwjht"},"outputs":[],"source":["import pandas as pd\n","\n","# Apply t-SNE on embeddings\n","tsne = TSNE(n_components=2, random_state=42)\n","embedding_tsne = tsne.fit_transform(embedding_vectors_train)\n","\n","# Visualize the t-SNE embeddings for the training set\n","plt.scatter(embedding_tsne[:, 0], embedding_tsne[:, 1], c=Y_train_encoded, cmap='viridis')\n","plt.title('t-SNE Visualization of Embeddings (Training Set)')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gJ1XcmnPIeeG"},"source":["# MODEL D - anomaly detection"]},{"cell_type":"markdown","metadata":{"id":"qHiOam3Q2520"},"source":["## Data loading and resizinge"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Q_28f-TIpS7"},"outputs":[],"source":["from google.colab import drive\n","import os\n","import cv2\n","import numpy as np\n","from zipfile import ZipFile\n","from io import BytesIO\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Function to load images from a folder and return X, Y\n","def load_images_from_folder(folder_path, image_size=(224, 224)):\n","    X = []  # Images\n","\n","    for filename in os.listdir(folder_path):\n","        img_path = os.path.join(folder_path, filename)\n","\n","        # Read the image using OpenCV\n","        img = cv2.imread(img_path)\n","\n","        # Resize if needed\n","        img = cv2.resize(img, image_size)\n","\n","        # Convert pixel values to floating point numbers\n","        img_float = img.astype('float32')\n","\n","        # Normalize pixel values to [0, 1]\n","        img_normalized = img_float / 255.0\n","\n","        # Append image\n","        X.append(img_normalized)\n","\n","    return np.array(X)\n","\n","path_train = '/content/drive/MyDrive/project_ML/all_the_images/train/NORMAL'\n","X_train = load_images_from_folder(path_train)\n","print(\"X_train shape:\", X_train.shape)\n","\n","path_val = '/content/drive/MyDrive/project_ML/all_the_images/val/NORMAL'\n","X_val = load_images_from_folder(path_val)\n","print(\"X_val shape:\", X_val.shape)"]},{"cell_type":"markdown","metadata":{"id":"AN8MoPji3BF2"},"source":["## The moddel - autoencoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_bWY22nIvpN"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","latent_dim = 64\n","\n","# Encoder\n","encoder_input = layers.Input(shape=(224,224,3))\n","\n","x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(encoder_input)\n","x = layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","latent_space = layers.MaxPooling2D((2, 2), padding='same')(x)\n","\n","encoder = models.Model(encoder_input, latent_space, name='encoder')\n","encoder.summary()\n","\n","# Decoder\n","decoder_input = layers.Input(shape=latent_space.shape[1:])\n","x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(decoder_input)\n","x = layers.UpSampling2D((2, 2))(x)\n","x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = layers.UpSampling2D((2, 2))(x)\n","x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","x = layers.UpSampling2D((2, 2))(x)\n","decoder_output = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","decoder = models.Model(decoder_input, decoder_output, name='decoder')\n","decoder.summary()\n","\n","# Autoencoder = Encoder + Decoder\n","autoencoder_input = layers.Input(shape=(224,224,3))\n","latent_space = encoder(autoencoder_input)\n","autoencoder_output = decoder(latent_space)\n","\n","autoencoder = models.Model(autoencoder_input, autoencoder_output, name='autoencoder')\n","custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","autoencoder.compile(optimizer=custom_optimizer, loss='binary_crossentropy')\n","autoencoder.summary()"]},{"cell_type":"markdown","metadata":{"id":"3iaGZcPU3Ffj"},"source":["## Traning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uAMXfnZII0us"},"outputs":[],"source":["import os\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# Define the directory path\n","directory_path = '/content/drive/My Drive/models_and_weights/D/'\n","\n","# Create the directory if it doesn't exist\n","if not os.path.exists(directory_path):\n","    os.makedirs(directory_path)\n","\n","# Save the model architecture to Google Drive\n","autoencoder.save('/content/drive/My Drive/models_and_weights/D/model.keras')\n","\n","# Define the filepath for saving the best weights\n","checkpoint_filepath_anomaly = '/content/drive/My Drive/models_and_weights/D/weights.model.keras'\n","\n","# Define the callback to save the best weights\n","checkpoint_callback_anomaly = ModelCheckpoint(\n","    filepath=checkpoint_filepath_anomaly,\n","    save_weights_only=True,\n","    monitor='val_loss',  # Monitor validation loss\n","    mode='min',          # Minimize validation loss\n","    save_best_only=True,  # Save only the best weights\n","    verbose=1            # Print messages indicating when weights are saved\n",")\n","\n","# Train the anomaly detection model with the callback\n","history_anomaly = autoencoder.fit(\n","    X_train, X_train,\n","    epochs=10,\n","    batch_size=50,\n","    shuffle=True,\n","    validation_data=(X_val, X_val),\n","    callbacks=[checkpoint_callback_anomaly]\n",")"]},{"cell_type":"markdown","metadata":{"id":"ABy_GeDbdRG5"},"source":["## Plot Accuracy and Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oyls7tWsdX_S"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Check if acc is not None\n","if acc is not None:\n","    epochs = range(len(acc))\n","    ## Plot accuracy\n","    plt.plot(epochs, acc, 'r', label='Training accuracy')\n","    if 'val_accuracy' in history_anomaly.history:\n","        val_acc = history_anomaly.history['val_accuracy']\n","        plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","    plt.title('Training and validation accuracy')\n","    plt.legend(loc=0)\n","    plt.figure()\n","    plt.show()\n","\n","# Plot Loss\n","loss = history_anomaly.history['loss']\n","val_loss = history_anomaly.history['val_loss']\n","epochs = range(len(loss))\n","plt.plot(epochs, loss, 'r', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation Loss')\n","plt.legend(loc=0)\n","plt.figure()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ET92QWfG3X8P"},"source":["##  Loading data for testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkSOHb2ji_92"},"outputs":[],"source":["# used images from traing we didnt use in order to test and see results\n","def test_load_images_from_folder(folder_path, target_size=(224, 224)): ## instead of 224\n","    X = []  # Images\n","    y = []  # Labels\n","\n","    for label in os.listdir(folder_path):\n","        label_folder = os.path.join(folder_path, label)\n","\n","        # Ensure it's a directory\n","        if os.path.isdir(label_folder):\n","            for filename in os.listdir(label_folder):\n","                img_path = os.path.join(label_folder, filename)\n","\n","                img = cv2.imread(img_path)\n","                # Resize if needed\n","                img = cv2.resize(img, target_size)\n","                # Normalize pixel values\n","                img = img.astype('float32')\n","                img = img / 255.0\n","\n","                subfolder_name = os.path.basename(label_folder)\n","\n","                X.append(img)\n","                y.append(subfolder_name)\n","\n","    return np.array(X), np.array(y)\n","\n","\n","path_test = '/content/drive/MyDrive/project_ML/all_the_images/test'\n","X_test, Y_test = test_load_images_from_folder(path_test)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"Y_test shape:\", Y_test.shape)\n","unique_labels = np.unique(Y_test)\n","print(\"Test Unique Labels:\", unique_labels)"]},{"cell_type":"markdown","metadata":{"id":"AYQ1sEi-3bSh"},"source":["## Anomaly Detection and Evaluation  - THRESHOLD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8O9ovsyJRCm"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","# Calculate reconstruction loss for validation images\n","reconstructed_images_val = autoencoder.predict(X_val)\n","val_loss = tf.keras.losses.binary_crossentropy(X_val, reconstructed_images_val)\n","val_loss = tf.keras.backend.eval(val_loss)\n","\n","val_loss_means = []\n","for loss in val_loss:\n","  val_loss_means.append(np.mean(loss))\n","\n","# threshold\n","threshold = np.mean(val_loss_means)\n","\n","# Save the threshold to a file\n","threshold_file_path = '/content/drive/My Drive/models_and_weights/D/threshold.txt'\n","with open(threshold_file_path, 'w') as file:\n","    file.write(str(threshold))\n","\n","# Plot histogram of reconstruction losses\n","plt.hist(val_loss_means, bins=30 , color='blue', alpha=0.7)\n","plt.xlabel('Reconstruction Loss')\n","plt.ylabel('Frequency')\n","plt.title('Histogram of Reconstruction Losses')\n","plt.axvline(threshold, color='red', linestyle='dashed', linewidth=2, label=f'Threshold: {threshold:.2f}') # Add threshold line to the histogram\n","plt.legend()\n","plt.show()\n","\n","# Detect anomalies\n","anomalies_idx = np.where(val_loss_means > threshold)[0]\n","\n","# Plot some normal and anomalous images\n","plt.figure(figsize=(20, 4))  # Adjust the figure size\n","num_anomalies = len(anomalies_idx)\n","num_plots = min(6, num_anomalies + 3)  # Ensure we plot at most 6 images\n","indices_to_plot = [1, 3, 5] + anomalies_idx.tolist()[:3]  # Indices to plot: 3 normal + 3 anomalies (if available)\n","\n","# Create subplots\n","fig, axes = plt.subplots(2, num_plots, figsize=(20, 8))\n","\n","for i, idx in enumerate(indices_to_plot):\n","    # Check if index is valid\n","    if idx < len(X_val):\n","        # Plot original image\n","        axes[0, i].imshow(X_val[idx].reshape(224, 224, 3))\n","        if idx in anomalies_idx:\n","            axes[0, i].set_title(\"Original Anomaly\")  # Set title as \"Anomaly\" for anomalous images\n","        else:\n","            axes[0, i].set_title(\"Original Normal\")   # Set title as \"Normal\" for normal images\n","        axes[0, i].axis('off')\n","\n","        # Plot corresponding reconstructed image\n","        axes[1, i].imshow(reconstructed_images_val[idx].reshape(224, 224, 3))\n","        if idx in anomalies_idx:\n","            axes[1, i].set_title(\"Reconstructed Anomaly\")  # Set title as \"Reconstructed Anomaly\" for anomalous images\n","        else:\n","            axes[1, i].set_title(\"Reconstructed Normal\")   # Set title as \"Reconstructed Normal\" for normal images\n","        axes[1, i].axis('off')\n","    else:\n","        # If the index is out of range, leave the subplot empty\n","        axes[0, i].axis('off')\n","        axes[1, i].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"lR-Fa2y33gE6"},"source":["##  Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2DWEIokPMeu"},"outputs":[],"source":["from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Calculate reconstruction loss for validation images\n","reconstructed_images_test = autoencoder.predict(X_test)\n","test_loss = tf.keras.losses.binary_crossentropy(X_test, reconstructed_images_test)\n","test_loss = tf.keras.backend.eval(test_loss)\n","\n","predicted_labels_test = []\n","test_loss_means = []\n","\n","# Iterate over each reconstruction loss in test_loss\n","for loss in test_loss:\n","    mean_loss = np.mean(loss)\n","    test_loss_means.append(mean_loss)\n","    # Check if the loss is greater than the threshold\n","    if mean_loss > threshold:\n","        # If so, append 'anomaly' to the predicted_labels_test list\n","        predicted_labels_test.append('anomaly')\n","    else:\n","        # Otherwise, append 'normal'\n","        predicted_labels_test.append('NORMAL')\n","\n","print(\"threshold: \", threshold, \"\\n\")\n","\n","# Print the predicted and true labels for the test set and also loss val for each image\n","for i, (predicted_label, true_label, test_image_loss) in enumerate(zip(predicted_labels_test, Y_test, test_loss_means)):\n","    print(f\"Image {i}: Predicted Label - {predicted_label}, True Label - {true_label}, Loss Val - {test_image_loss}\")\n","\n","# Map \"pneumonia\" to \"anomaly\" in Y_test\n","Y_test_mapped = np.where(Y_test == \"PNEUMONIA\", \"anomaly\", Y_test)\n","\n","# Combine true and predicted labels\n","all_labels = np.concatenate([Y_test_mapped, predicted_labels_test])\n","\n","# Initialize LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","# Fit LabelEncoder on combined labels\n","label_encoder.fit(all_labels)\n","\n","# Convert string labels to numerical labels\n","Y_test_encoded = label_encoder.transform(Y_test_mapped)\n","predicted_labels_test_encoded = label_encoder.transform(predicted_labels_test)\n","\n","# Generate classification report\n","report = classification_report(Y_test_encoded, predicted_labels_test_encoded, target_names=label_encoder.classes_)\n","print(\"Classification Report:\")\n","print(report)\n","\n","# Generate confusion matrix\n","conf_matrix = confusion_matrix(Y_test_encoded, predicted_labels_test_encoded)\n","print(\"Confusion Matrix:\")\n","\n","# Define labels for the confusion matrix\n","labels = [\"NORMAL\", \"anomaly\"]\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Confusion Matrix')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["dpKJYS62rTWR","POtUmIC2HsCQ","Ynd82BIRDgiH","MCK2sXcVDj0o","T56auUmqDnh8","ANCERjdvPd_E","c2xLkniYIvan","z7ojPFCtDqXB","D-uE5UNQ2gXn","n7VEGGrmHTNp","7azE_IxKrxaQ","DTQz7OUfSyme","C9OSWVn4DGOO","zxteJEL3DPDj","Ps2-IRUlDTFq","krsTkEm7VmIk","iokNzLGsJYCT","g5S26y9GDXVx","4JZEi6OJSp70","MpCruNYV9XyI","hJl3WT9kOmZP","CXb8ca6DOU5b","U8N7kzRoOgfD","OUj-PIG0OcrN","gJ1XcmnPIeeG","fzJZREp0t_TR","qHiOam3Q2520","AN8MoPji3BF2","3iaGZcPU3Ffj","ABy_GeDbdRG5","ET92QWfG3X8P","AYQ1sEi-3bSh","lR-Fa2y33gE6","Q2UE1ABCtYyd","tcp034GA3IZm","XT2dxRYZ3OUO","1fyOvBJ9d_Ax"],"gpuType":"T4","provenance":[{"file_id":"1iz5kdaQ4Fy5mQpViMbOrNQvzSIeqx8Cu","timestamp":1713207100710}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
